{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17283043",
   "metadata": {},
   "source": [
    "# Test With All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3b0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143e9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dce23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../artifacts/raw/raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94f6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Delivery_Time\", \"Order_ID\"])\n",
    "y = df[\"Delivery_Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63110e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d6a966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6108469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features: ['Order_Date', 'Order_Time', 'Pickup_Time', 'Weather', 'Traffic', 'Vehicle', 'Area', 'Category', 'DayOfWeek']\n",
      "Numeric Features: ['Agent_Age', 'Agent_Rating', 'Store_Latitude', 'Store_Longitude', 'Drop_Latitude', 'Drop_Longitude', 'Distance_km', 'Order_Hour', 'Day_Of_Week', 'Pickup_Delay']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categorical Features:\", cat_cols)\n",
    "print(\"Numeric Features:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7399cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bdd2043",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(objective=\"reg:squarederror\", eval_metric=\"rmse\"),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"KNN Regressor\": KNeighborsRegressor(),\n",
    "    \"LGBMRegressor\" : LGBMRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ae54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "121c7fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\OneDrive\\Desktop\\Amazon Delivery Time Prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    # Create pipeline (encoding + model)\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"model\", model)])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results.append([name, rmse, mae, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a1599cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "\n",
      "                       Model       RMSE        MAE  R2 Score\n",
      "13             LGBMRegressor  21.979246  17.112851  0.816304\n",
      "8              Random Forest  22.587027  17.340061  0.806004\n",
      "10                   XGBoost  22.760143  17.729929  0.803019\n",
      "9          Gradient Boosting  24.575352  19.035239  0.770346\n",
      "3              Decision Tree  30.559340  22.792178  0.644891\n",
      "7              Decision Tree  30.586232  22.768896  0.644266\n",
      "4          Linear Regression  31.655251  25.100438  0.618965\n",
      "0          Linear Regression  31.655251  25.100438  0.618965\n",
      "1                      Ridge  31.660001  25.100963  0.618850\n",
      "5                      Ridge  31.660001  25.100963  0.618850\n",
      "6                      Lasso  34.231919  26.851554  0.554409\n",
      "2                      Lasso  34.231919  26.851554  0.554409\n",
      "12             KNN Regressor  46.749800  36.016493  0.168938\n",
      "11  Support Vector Regressor  49.360900  39.296804  0.073512\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"RMSE\", \"MAE\", \"R2 Score\"])\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "print(results_df.sort_values(by=\"RMSE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53617331",
   "metadata": {},
   "source": [
    "# Test With Top 15 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2fe882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a41d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../artifacts/raw/raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5781d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Delivery_Time\", \"Order_ID\"])\n",
    "y = df[\"Delivery_Time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "359db67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "841b1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c283f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 Features Selected: ['cat__Category_Grocery', 'num__Agent_Rating', 'cat__Traffic_Low', 'num__Distance_km', 'num__Agent_Age', 'cat__Weather_Sunny', 'cat__Weather_Cloudy', 'cat__Weather_Fog', 'cat__Vehicle_motorcycle', 'cat__Traffic_Medium', 'num__Drop_Longitude', 'num__Drop_Latitude', 'cat__Traffic_Jam', 'num__Store_Longitude', 'num__Store_Latitude']\n",
      "\n",
      "Model Comparison (Top 15 Features):\n",
      "\n",
      "                      Model       RMSE        MAE  R2 Score\n",
      "9             LGBMRegressor  22.152983  17.228092  0.813389\n",
      "6                   XGBoost  22.929962  17.806622  0.800069\n",
      "4             Random Forest  23.684803  18.058934  0.786689\n",
      "5         Gradient Boosting  24.820469  19.290728  0.765742\n",
      "3             Decision Tree  31.312717  23.079118  0.627166\n",
      "1                     Ridge  32.830680  25.974115  0.590142\n",
      "0         Linear Regression  32.833050  25.981877  0.590083\n",
      "2                     Lasso  34.629407  27.168219  0.544001\n",
      "8             KNN Regressor  42.051205  32.017364  0.327595\n",
      "7  Support Vector Regressor  49.418508  39.340940  0.071348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sumit\\OneDrive\\Desktop\\Amazon Delivery Time Prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1. Encode Full Dataset\n",
    "# ----------------------------\n",
    "X_full = preprocessor.fit_transform(X)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Fit Random Forest on Encoded Data\n",
    "# ----------------------------\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(X_full, y)\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "})\n",
    "\n",
    "# Get top 15 features (exact encoded names)\n",
    "top_15_features = feat_imp.sort_values(by=\"Importance\", ascending=False).head(15)[\"Feature\"].tolist()\n",
    "print(\"\\nTop 15 Features Selected:\", top_15_features)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Select Top 15 Feature Columns\n",
    "# ----------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get indices of top features\n",
    "top_idx = [list(feature_names).index(f) for f in top_15_features]\n",
    "\n",
    "X_train_top = X_train[:, top_idx]\n",
    "X_test_top = X_test[:, top_idx]\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Train Models on Top 15 Features\n",
    "# ----------------------------\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(objective=\"reg:squarederror\", eval_metric=\"rmse\"),\n",
    "    \"Support Vector Regressor\": SVR(),\n",
    "    \"KNN Regressor\": KNeighborsRegressor(),\n",
    "    \"LGBMRegressor\" : LGBMRegressor()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_top, y_train)\n",
    "    preds = model.predict(X_test_top)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, preds)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "\n",
    "    results.append([name, rmse, mae, r2])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"RMSE\", \"MAE\", \"R2 Score\"])\n",
    "print(\"\\nModel Comparison (Top 15 Features):\\n\")\n",
    "print(results_df.sort_values(by=\"RMSE\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98993283",
   "metadata": {},
   "source": [
    "## What the Results Say\n",
    "### All Features\n",
    "\n",
    "- Best models:\n",
    "\n",
    "    - LGBMRegressor (RMSE ~ 21.98, RÂ² ~ 0.816)\n",
    "\n",
    "    - Random Forest (RMSE ~ 22.58, RÂ² ~ 0.806)\n",
    "\n",
    "    - XGBoost (RMSE ~ 22.76, RÂ² ~ 0.803)\n",
    "\n",
    "### Top 15 Features\n",
    "\n",
    "- Best models:\n",
    "\n",
    "    - LGBMRegressor (RMSE ~ 22.15, RÂ² ~ 0.813)\n",
    "\n",
    "    - XGBoost (RMSE ~ 22.93, RÂ² ~ 0.800)\n",
    "\n",
    "    - Random Forest (RMSE ~ 23.68, RÂ² ~ 0.786)\n",
    "\n",
    "### ðŸ”¹ Interpretation\n",
    "\n",
    "- Performance is very similar between all features and top 15 features.\n",
    "\n",
    "    - LGBM: 21.98 â†’ 22.15 RMSE (almost no change).\n",
    "\n",
    "    - Random Forest: 22.58 â†’ 23.68 RMSE (slight drop).\n",
    "\n",
    "    - XGBoost: 22.76 â†’ 22.93 RMSE (almost identical).\n",
    "\n",
    "ðŸ‘‰ This means most predictive power is concentrated in the top 15 features.\n",
    "\n",
    "### ðŸ”¹ What to Do\n",
    "\n",
    "### 1. If you want maximum accuracy â†’ Use all features with LGBM / RF / XGBoost.\n",
    "\n",
    "- Slightly better performance.\n",
    "\n",
    "- But more complex model.\n",
    "\n",
    "### 2. If you want interpretability & efficiency â†’ Use top 15 features.\n",
    "\n",
    "- Model is simpler, easier to explain.\n",
    "\n",
    "- Very small drop in accuracy (â‰ˆ 0.3â€“1 RMSE difference)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb23d58",
   "metadata": {},
   "source": [
    "# Final Conclusion :- \n",
    "- Choosing Model with top 15 features because of less model complexity and lesser model size , easy to deploy because of ***lightgbm***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
